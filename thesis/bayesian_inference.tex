\chapter{Bayesian inference}
We present essential concepts in Bayesian parameter inference and several methods to estimate
posterior distribution. The methods range from posterior conjugations, in which tractability is
guaranteed as we know the analytic form of both likelihood and prior distribution. Afterwards, we
discuss different sampling algorithm to approximate the posterior distribution when no conjugations
are available. We also present a likelihood-free method to exploit in the case that the analytical
form of the likelihood is not achievable or is too complex to evaluate. The sampling algorithms
presented in this chapter are the building block for the Bayesian frameworks that we present in this
thesis.

\section{Bayesian inference}
\subsection{Bayesian formula}
Let $D_{obs}$ be observed data. In statistical inference, we assume that the observed data has a
probability distribution of unknown parameter $\theta$, that is $D_{obs} \sim P(D_{obs}|\theta)$.
There are two main approaches in statistical inference: frequentist approach and Bayesian approach.
In the frequentist approach, the estimation of $\theta$ is based on long-run property, that is, given a
large enough sample size, expected value of parameter estimation $\hat{\theta}$ is equal to
$\theta$. Therefore, frequentist approach requires to gather a large amount of data to deliver a
close estimation $\hat{\theta}$.  The main advantage of Bayesian approach over frequentist approach
is that it require less data to obtain an estimation $\hat{\theta}$.\\
In Bayesian approach, we use the information gained from previously observed data \textit{(beliefs)}
to enhance the accuracy of the estimation of $\hat{\theta}$. The beliefs obtained from prior
knowledge of model parameter $\theta$ is represented by \textit{prior distribution} $\pi(\theta)$.
We have the \textit{likelihood} $P(D_{obs}|\theta)$ as the probability distribution over observed
data, given parameter $\theta$.
\begin{definition}[Bayes theorem]
    \rm
    \begin{align*}
        \pi(\theta | D_{obs}) = \frac{P(D_{obs}|\theta)\pi(\theta)}{\int_\theta P(D_{obs}|\theta)\pi(\theta)d\theta}
    \end{align*}
    where
    \begin{itemize}
        \item $\pi(\theta)$ is the \textit{prior distribution}.
        \item $P(D_{obs}|\theta)$ is the \textit{likelihood}.
        \item $\int_\theta P(D_{obs}|\theta)\pi(\theta)d\theta$ is the \textit{marginal distribution}.
        \item $\pi(\theta | D_{obs})$ is the \textit{posterior distribution}
    \end{itemize}
\end{definition}
The essential part of Bayesian inference in statistic is to compute or estimate the posterior
distribution. From the analytical form or the samples from the posterior distribution, we estimate
the model parameter $\theta$.

\subsection{Bayesian parameter estimation}
With posterior distribution $\pi(\theta|D_{obs})$ we estimate the parameter $\hat{\theta}$ using Bayesian
posterior mean.
\begin{definition}[Bayesian posterior mean]
    \rm
    \begin{align*}
        \hat{\theta} = \mathbf{E}[\theta] = \int_\theta \theta \pi(\theta|D_{obs}) d\theta
    \end{align*}
\end{definition}
In case we have samples from posterior distribution, for example a trace of $N$ parameter values
$(\theta_1,\ldots,\theta_N)$ sampled from the posterior distribution $\pi(\theta|D_{obs})$, the
discrete form of posterior mean is used:
\begin{align*}
    \hat{\theta} \approx \mathbf{E}[\theta] \approx \sum_\theta \theta \pi(\theta|D_{obs})
\end{align*}

\begin{definition}[Bayesian Credible Set]
    Set C is a $(1 − \alpha )100\%$ credible set for the parameter $\theta$ if the posterior
    probability for $\theta$ to belong to C equals $(1 − \alpha)$.
    \begin{align*}
        P(\theta \in C | D_{obs}) = \int_C \pi(\theta|D_{obs}) d\theta = 1 - \alpha
    \end{align*}
\end{definition}
In this thesis, we use by default $0.95$ credible set, which corresponds to $\alpha=0.05$
\begin{definition}[Highest Posterior Density credible set]
    Highest Posterior Density $(1-\alpha)100\%$ credible set (HPD for short) is the
    interval with minimum length over all Bayesian $(1-\alpha)100\%$ Credible Set.
\end{definition}

In this research, the HPD is calculated using algorithm from \textit{PyMC3} library
\cite{salvatier2016pymc3}. For simplicity, we assume that in all cases which we concern, HPD is
computed using the algorithm for unimodal distribution.
\begin{algorithm}[H]
    \footnotesize{
        \hspace*{\algorithmicindent} \textbf{Input:}
        \begin{itemize}[noitemsep,topsep=0pt]
            \item $S$: is samples from a distribution.
            \item $0\leq \alpha \leq 1$: confidence level.
        \end{itemize}
        \hspace*{\algorithmicindent} \textbf{Output:} HPD interval.
    }
    \begin{algorithmic}[1]
        \Procedure{Compute HPD}{$S$}
        \State Compute interval width $w = |S| * \alpha$
        \State Find modal (peak) of sample points.
        \State Return minimal interval of size $|S| - w$ which contains the modal.
        \EndProcedure
    \end{algorithmic}
    \caption{Compute Highest Posterior Density Interval}
    \label{alg:hpd}
\end{algorithm}

\subsection{Selection of prior distribution}
Theoretically in Bayesian inference, prior distribution can be of any distribution family. However,
a selection of prior distribution that is too different than the actual distribution of parameter
can leads to a false propagation of beliefs and degrade the inference results. It is suggested by
\cite{polgreen2016data} that in case of no prior knowledge exists, Uniform distribution is
preferable since it is less likely to propagate false beliefs to the inference. In this thesis, we
use uniform distribution as the prior distribution on model parameters.

\subsection{Estimation of posterior distribution}
\subsubsection{Posterior conjugation}
Conjugated posteriors are special cases of Bayesian inference, in which the prior and posterior
distribution belongs to the same family of distribution. When posterior conjugation is applicable,
only the parameters of probability distribution function need to be re-estimated. Applying
conjugated posterior when it is possible gives advantages:
\begin{itemize}
    \item Tractability: we have analytical form of posterior distribution with only changes in its
          parameters.
    \item Computationally effective: updating model parameter is of linear time to the dimension of
          parameter.
\end{itemize}
We consider two conjugated posteriors as examples: Binomial-Beta and Dirichlet-Multinomial.
\begin{lemma}[Binomial-Beta Conjugation]
    Binomial distribution is conjugated to beta distribution.
\end{lemma}
\begin{proof}
    The observed data $D=(x_1,\ldots,x_n)$ is sampled from $Binomial(k, \theta)$ function
    \begin{align*}
        P(D|\theta) = \prod_{i=1}^n{k\choose x_i}\theta^{x_i}(1-\theta)^{k-x_i}
    \end{align*}
    The parameter $\theta$ is of $Beta(\alpha, \beta)$ distribution
    \begin{align*}
        \pi(\theta) = \theta^{\alpha-1}(1-\theta)^{\beta -1}
    \end{align*}
    We obtained:
    \begin{align*}
        \pi(\theta|D) & \sim P(D|\theta)\pi(\theta)                                                                             \\
                      & \sim \theta^{\sum_{i=1}^n x_i}(1-\theta)^{nk -\sum_{i=1}^n x_i} \theta^{\alpha -1} (1-\theta)^{\beta-1} \\
                      & = \theta^{\alpha - 1 + \sum_{i=1}^n x_i}(1-\theta)^{\beta - 1 + nk -\sum_{i=1}^n x_i}
    \end{align*}
    Thus, the posterior is $Beta(\alpha + \sum_{i=1}^n x_i, \beta + nk -\sum_{i=1}^n x_i)$
\end{proof}
Generalize this conjugation, we also have Multinomial-Dirichlet conjugation.
\begin{lemma}[Multinomial-Dirichlet Conjugation]
    Multinomial distribution is conjugated to Dirichlet distribution.
\end{lemma}
\begin{proof}
    The observed data $D=(x_1,\ldots,x_n)$ is sampled from $Multinomial(n; \theta_1,\ldots,\theta_n)$ function
    \begin{align*}
        P(x_1,\ldots,x_n | N, \theta_0,\ldots,\theta_n) & = \frac{n!}{x_1!\ldots x_n!} \prod_{i=1}^n\theta_i^{x_i}
    \end{align*}
    The parameter $(\theta_1,\ldots,\theta_n)$ is
    $Dirichlet(\alpha_1,\ldots,\alpha_n)$
    \begin{align*}
        \pi(\theta_1,\ldots,\theta_n) = \frac{1}{\mathbf{B}(\alpha_1,\ldots,\alpha_n)}\prod_{i=1}^n\theta_i^{\alpha_i - 1}
    \end{align*}
    We obtain
    \begin{align*}
        \pi(\theta_1,\ldots,\theta_n|D) & \sim P(D|\theta)\pi(\theta)                                           \\
                                        & \sim \prod_{i=1}^n\theta_i^{x_i} \prod_{i=1}^n\theta_i^{\alpha_i - 1} \\
                                        & \sim \prod_{i=1}^n\theta_i^{\alpha_i - 1 + \sum_{i=1}^n x_i}
    \end{align*}
    Thus, the posterior is $Dirichlet(\alpha_1 +  x_1,\ldots,\alpha_n
        +  x_n)$
\end{proof}
More detailed description in these cases can be found in \cite{tu2014dirichlet}
and \cite{baron2019probability}. We summarize the necessary results in the following table:
\begin{table}[H]
    \begin{tabular}{lllll}
        \cline{1-3}
        \multicolumn{1}{|l|}{Likelihood}                                 & \multicolumn{1}{l|}{Prior}                                 & \multicolumn{1}{l|}{Posterior parameters}                         &  & \\ \cline{1-3}
        \multicolumn{1}{|l|}{$Binomial(n, k)$}                           & \multicolumn{1}{l|}{$Beta(\alpha, \beta)$}                 & \multicolumn{1}{l|}{\begin{tabular}[x]{@{}c@{}}$\alpha' = \alpha + \sum_{i=1}^n x_i$\\$\beta' = \beta + nk -\sum_{i=1}^n x_i$\end{tabular}}                   &  & \\ \cline{1-3}
        \multicolumn{1}{|l|}{$Multinomial(n; \theta_1,\ldots,\theta_n)$} & \multicolumn{1}{l|}{$Dirichlet(\alpha_1,\ldots,\alpha_n)$} & \multicolumn{1}{l|}{$\alpha_i' =\alpha_i + x_i, 1 \leq i \leq n$} &  & \\ \cline{1-3}
                                                                         &                                                            &                                                                   &  &
    \end{tabular}
\end{table}
However, posterior conjugation is applicable to a subset of prior and likelihood functions. In
Bayesian inference, it is common that the posterior distribution has no analytical form or its
analytical form is difficult to directly sample from. In these cases, we can several different
sampling and optimization methods to approximate the posterior distribution. In the following
section we discuss different approaches for posterior distribution approximation:
\begin{itemize}
    \item Markov chain Monte Carlo.
    \item Sequential Monte Carlo.
    \item Approximate Bayesian Computation.
\end{itemize}

\subsubsection{Markov chain Monte Carlo}
In case the posterior distribution has no analytical form or its analytical form is difficult to
sample from directly, we use \textit{Metropolis-Hastings} algorithm  (\textit{MH} in short). Firstly
introduced by Metropolis \cite{metropolis1953equation} and later generalized by Hastings
\cite{hastings1970monte} Metropolis-Hastings algorithm is a \textit{Monte Carlo Markov Chain}
algorithm. In its essential, Metropolis-Hastings algorithm draws sample from an unknown
distribution. Using the MH algorithm, we can estimate the parameter by posterior mean, without
knowing the analytical form of posterior distribution itself. A special case of MH algorithm is
Gibbs sampling algorithm \cite{geman1984stochastic}, in which candidates are accepted with
probability 1. Gibbs sampling can be used to draw samples from multivariate posteriors when the
parameter is of high dimensional. Quality of data can also impacts the estimation result from
Metropolis-Hastings algorithm; in case of experiment data is acquired from a small sample size,
statistical techniques to improve data quality can be used, for example \textit{bootstrapping}
\cite{efron1992bootstrap}.

\begin{algorithm}[H]
    \caption{Metropolis-Hastings Algorithm}
    \label{alg:mh}
    \footnotesize{
        \hspace*{\algorithmicindent} \textbf{Input:}
        \begin{itemize}[noitemsep,topsep=0pt]
            \item Model $\mathcal{M}_\theta$
            \item $D_{obs}$: observation data
            \item $P(D|\theta)$: likelihood function
            \item $\pi(\theta)$: prior distribution
            \item Transition kernel $Q(\theta^t|\theta^{t-1})$
            \item $N$ number of particles.
        \end{itemize}
        \hspace*{\algorithmicindent} \textbf{Output:}
        \begin{itemize}[noitemsep,topsep=0pt]
            \item $(\theta_1,\ldots,\theta_N)$ sample of $N$ particles
            \item $(w_1,\ldots,w_N)$ corresponding likelihoods.
        \end{itemize}
    }
    \begin{algorithmic}[1]
        \Procedure{Metropolis-Hastings}{}
        \State Draw $\theta_{cand}$ from $\pi(\theta)$
        \State $\theta_1 \leftarrow  \theta_{cand}$
        \State $w_1 \leftarrow  \ln(P(D_{obs}|\theta_{cand}))$
        \State $i \leftarrow 2$
        \While{$i \leq N_{MH}$}
        \State Draw $\theta_{cand}$ from $Q(\theta'|\theta_{i-1})$
        \If{ $\ln(P(D_{obs}|\theta_{cand})) - \ln(P(D_{obs}|\theta_{i-1})) > 0$ }
        \State $\theta_i \leftarrow \theta_{cand}$
        \State $w_i \leftarrow \ln(P(D_{obs}|\theta_{cand}))$
        \State $i \leftarrow i + 1$
        \Else
        \State Draw a random number $u$ from $Uniform(0,1)$
        \If{$u \leq \xi$, ($\xi$ small, e.g $10^{-2}$)}
        \State $\theta_i \leftarrow \theta_{cand}$
        \State $w_i \leftarrow \ln(P(D_{obs}|\theta_{cand}))$
        \State $i \leftarrow i + 1$
        \EndIf
        \EndIf
        \EndWhile
        \State Return $(\theta_1,\ldots,\theta_{N}})$, $(w_1,\ldots,w_{N}})$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

The likelihood function can be implemented as log-likelihood to avoid underflow error.
Advantages of Metropolis-Hastings are:
\begin{itemize}
    \item[+] Parameter transition only needs the computation of likelihood function.
          Therefore, Monte Carlo Markov Chain can be used in general Bayesian inference,
          in which we are not guaranteed to have an analytical form of posterior.
    \item[+] Computationally efficient; as marginal distribution is cancelled out, and likelihood can
          be replaced by log-likelihood, Metropolis-Hastings simplifies the computation of Bayes formula
          and avoid infinitesimal values.
    \item[+] Simple to implement.
\end{itemize}
Disadvantages of Metropolis-Hastings are
\begin{enumerate}
    \item[-] Particle in Metropolis-Hastings algorithm moves in a linear Markov chain; it is highly
          probable to be stuck in a local maximum or minimum.
    \item[-] Not parallelizable; since there is only one linear chain, and current step depends on
          previous step, Metropolis-Hastings algorithm does not scale up to multi-processors.
\end{enumerate}
The next algorithm, \textit{Sequential Monte Carlo}, addresses the issues of Metropolis-Hastings.

\subsubsection{Sequential Monte Carlo}
Sequential Monte Carlo method is firstly proposed by Del \cite{del2006sequential}. Instead of having
one particle moving in its parameter space, Sequential Monte Carlo estimates by using $N$ particles
moving independently. In its initial step, Sequential Monte Carlo draws a parameter candidate from
the prior distribution. In each iteration, it then mutates parameter candidates through a series of
\textit{perturbation kernels} and select parameter candidates for the next iteration with regarding
to their weights. By sampling from $N$ independently moving particles, Sequential Monte Carlo method
has a significant advantage of easily parallelizable. Furthermore, Daviet \cite{daviet2018inference}
shows that Sequential Monte Carlo delivers better performance on approximating multimodal
distribution.

\begin{algorithm}[H]
    \caption{Sequential Monte Carlo Algorithm}
    \label{alg:smc}
    \footnotesize{
        \hspace*{\algorithmicindent} \textbf{Input:}
        \begin{itemize}[noitemsep]
            \item Model $\mathcal{M}_\theta$
            \item $D_{obs}$: observation data
            \item $\pi(\theta)$: prior distribution
            \item $P(D|\theta)$: Likelihood function.
            \item $Q(\theta^t|\theta^{t-1})$: Transition kernel.
            \item $F_t(\theta^t|\theta_1^{t-1},\ldots,\theta_N^{t-1})$: Perturbation kernels
            \item $N$ number of particles.
        \end{itemize}
        \hspace*{\algorithmicindent} \textbf{Output:}
        \begin{itemize}[noitemsep]
            \item $(\theta_1,\ldots,\theta_N)$ sample of $N$ particles
            \item $(w_1,\ldots,w_N)$ corresponding likelihoods.
        \end{itemize}
    }
    \begin{algorithmic}[1]
        \Procedure{Sequential-Monte Carlo}{}
        \State $i \leftarrow 1$
        \While{$i \leq N$} \algorithmiccomment {SMC initialization}
        \State Draw $\theta$ from $\pi(\theta)$
        \State $\theta_i \leftarrow \theta$
        \State $w_i \leftarrow P(D_{obs}|\theta_i)$
        \State $i \leftarrow i + 1$
        \EndWhile
        \State $t \leftarrow 1$
        \While{$t \leq M$}
        \State $i \leftarrow 1$ \algorithmiccomment{SMC correction step}
        \While{$i \leq N$}
        \State $w'_i \leftarrow \frac{w_i}{\sum_{i=1}^N w_i} $
        \EndWhile
        \State Sample with replacement $(\theta'_1,\ldots,\theta'_N)$ \algorithmiccomment{SMC selection step} \\\hspace{1.5cm} from $(\theta_1,\ldots,\theta_N)$ with probabilities $(w'_1,\ldots,w'_N)$
        \State $(\theta_1,\ldots,\theta_N) \leftarrow (\theta'_1,\ldots,\theta'_N)$
        \State $i \leftarrow 1$
        \While{$i \leq N$} \algorithmiccomment {SMC perturbation step}
        \State Draw $\hat{\theta}^t_i$ from $F_t(\theta^t | \theta^{t-1}_1,\ldots,\theta^{t-1}_N), 1\leq t \leq M$
        \State $(\theta^*_1,\ldots,\theta^*_{N_{MH}}), (w^*_1,\ldots,w^*_{N_{MH}}) \leftarrow Metropolis-Hastings(\hat{\theta}^t_i)$
        \State $\theta_i \leftarrow \theta^*_{N_{MH}}$
        \State $w_i \leftarrow w^*_{N_{MH}}$
        \EndWhile
        \EndWhile
        \State Return $(\theta_1,\ldots,\theta_{N})$, $(w_1,\ldots,w_{N})$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
Selection of kernel function for SMC is mentioned by Filippi \cite{filippi2013optimality}, and Silk \cite{silk2012optimizing}.\\
Advantages of Sequential Monte Carlo algorithm:
\begin{itemize}
    \item[+] Approximate multimodal distributions: since Sequential Monte Carlo consists of $N$
          particles moving independently and later selected with replacement, it is less likely to fall
          into a local maximum or minimum.
    \item[+] Parallelizable: Sequential Monte Carlo has trivially data-parallelism, in contrast to
          Metropolis-Hastings where no parallelization is possible.
\end{itemize}
However, Sequential Monte Carlo also has disadvantages:
\begin{itemize}
    \item[-] Selection of perturbation and transition kernel is not trivial.
    \item[-] More difficult to implement.
\end{itemize}

\subsubsection{Approximate Bayesian Computation}
The methods mentioned before are used with an assumption that the likelihood $P(D_{obs}|\theta)$ has
an analytical form; the analytical form can be evaluated without introducing computational burden.
However for situations in which the likelihood has no analytical form, or the analytical form is
expensive to be evaluated, we use a class of \textit{likelihood-free methods}. Likelihood-free
methods in Bayesian inference estimates the likelihood $P(D_{obs}|\theta)$, or replace it by other
measures. \textit{Approximate Bayesian Computation} (or \textit{ABC} in short)
\cite{toni2009approximate} is a widely used likelihood-free method for approximating posterior
distribution. Instead of estimating the likelihood $P(D|\theta)$ directly, we define a distance
measure $\delta(D_1, D_2)$ where $D_1$ and $D_2$ denote observable data. Given a parameter candidate
$\hat{\theta}$ that specifies a model $\mathcal{M}_\theta$. The ABC algorithm accepts $\hat{\theta}$
if a simulation run on $\mathcal{M}_\theta$ delivers observable data $D_{sim}$ such that
$\delta(D_{obs},D_{sim}) < \epsilon$, where $\epsilon\in\mathbf{R}_{\leq 0}$ is the distance
threshold.
\begin{algorithm}[H]
    \caption{Approximate Bayesian Computation}
    \label{alg:abc-reject}
    \footnotesize{
        \hspace*{\algorithmicindent} \textbf{Input:}
        \begin{itemize}[noitemsep,topsep=0pt]
            \item Model $\mathcal{M}_\theta$
            \item $D_{obs}$: observation data
            \item $\pi(\theta)$: prior distribution
            \item $\delta(D_{sim}, D_{obs})$: distance function between two set of data simulated by $\mathcal{M}_\theta$
            \item $epsilon$: distance threshold
            \item $N$ number of particles.
        \end{itemize}
        \hspace*{\algorithmicindent} \textbf{Output:}
        \begin{itemize}[noitemsep]
            \item $(\theta_1,\ldots,\theta_N)$: $N$ sampled particles.
            \item $(w_1,\ldots,w_N)$: corresponding weights of sampled particles.
        \end{itemize}
    }
    \begin{algorithmic}[1]
        \Procedure{Approximate-Bayesian-Computation}{}
        \State Select a proposal distribution $\pi(\theta)$
        \State $i \leftarrow 1$
        \While{$i \leq N$}
        \State Draw a random particle $\theta$ from $\pi(\theta)$
        \State Simulate data $D_{sim}$ from $\mathcal{M}_\theta$
        \If{$d = \delta(D_{sim}, D_{obs}) < \epsilon$}
        \State $\theta_i \leftarrow \theta$
        \State $w_i = d$
        \EndIf
        \EndWhile
        \State Return $(\theta_1,\ldots,\theta_N)$, $(w_1,\ldots,w_N)$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
Advantages of Approximate Bayesian Computation:
\begin{itemize}
    \item[+] Likelihood-free: applicable when the likelihood has no analytical form or there is no likelihood.
    \item[+] Easy to implement.
\end{itemize}
Disavantages of Approximate Bayesian Computation:
\begin{itemize}
    \item[-] Which distances are proper to measure two data set? In the other word, is measuring
          distance a proper method to approximate likelihood?
    \item[-] How to select a threshold so that the likelihood is closely approximated?
\end{itemize}

\section{Summary}
We introduced basic concepts on Bayesian parameter inference and posterior estimation. Since the
posterior distributions normally have no analytical form, the presented sampling and
optimization methods which are essentials to posterior estimation. In the following chapter we
propose a data-driven approach for parameter synthesis combining Approximate Bayesian computation,
Sequential Monte Carlo, and Statistical Model Checking.
